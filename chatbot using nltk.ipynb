{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot Using Python NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A chatbot is an Artificial Intelligence software that can simulate a conversation with a user in natural language through messaging application, websites, mobile apps etc. These chatbot can be used in various industries for different purposes. \n",
    "\n",
    "Here I am trying to build a simple chatbot using NLTK library(Natural Language Toolkit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re \n",
    "from nltk.stem import wordnet # To perform lemmatization\n",
    "from sklearn.feature_extraction.text import CountVectorizer # To perform bow\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # To perform tfidf\n",
    "from nltk import pos_tag # For parts of speech\n",
    "from sklearn.metrics import pairwise_distances # To perform cosine similarity\n",
    "from nltk import word_tokenize # To create tokens\n",
    "from nltk.corpus import stopwords # for stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Text Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tell me about your personality</td>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want to know you better</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Define yourself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe yourself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tell me about yourself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Context  \\\n",
       "0  Tell me about your personality   \n",
       "1       I want to know you better   \n",
       "2                 Define yourself   \n",
       "3               Describe yourself   \n",
       "4          tell me about yourself   \n",
       "\n",
       "                                   Text Response  \n",
       "0    Just think of me as the ace up your sleeve.  \n",
       "1  I can help you work smarter instead of harder  \n",
       "2                                            NaN  \n",
       "3                                            NaN  \n",
       "4                                            NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_excel('dialog_talk_agent.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1592"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] # returns the number of rows in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above data contains 1592 data points and two columns context which can be inferred as the query and text response is the response for that query. we can see that there are null values in the dataset if we open the dataset in excel and observe we can find that in our dataset the data is in different clusters, the same type of questions in one place and then followed by next similar kind of questions.\n",
    "\n",
    "Null values are present for the same type of questions whose response can be almost similar and in that similar group of questions, the response is given to the first and the rest filled with null. So what we can do is use **ffill()** which returns the value of previous response in place of null values as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Text Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tell me about your personality</td>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want to know you better</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Define yourself</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe yourself</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tell me about yourself</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>can we chat</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>I'll be back in a few minutes</td>\n",
       "      <td>I'll be waiting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>I'll be back</td>\n",
       "      <td>All right. I'll be here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>I'll get back to you in a moment</td>\n",
       "      <td>Till next time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>I promise to come back</td>\n",
       "      <td>Okay. You know where to find me.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1592 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Context  \\\n",
       "0       Tell me about your personality   \n",
       "1            I want to know you better   \n",
       "2                      Define yourself   \n",
       "3                    Describe yourself   \n",
       "4               tell me about yourself   \n",
       "...                                ...   \n",
       "1587                       can we chat   \n",
       "1588     I'll be back in a few minutes   \n",
       "1589                      I'll be back   \n",
       "1590  I'll get back to you in a moment   \n",
       "1591            I promise to come back   \n",
       "\n",
       "                                      Text Response  \n",
       "0       Just think of me as the ace up your sleeve.  \n",
       "1     I can help you work smarter instead of harder  \n",
       "2     I can help you work smarter instead of harder  \n",
       "3     I can help you work smarter instead of harder  \n",
       "4     I can help you work smarter instead of harder  \n",
       "...                                             ...  \n",
       "1587                     Talking is what I do best.  \n",
       "1588                               I'll be waiting.  \n",
       "1589                       All right. I'll be here.  \n",
       "1590                                Till next time.  \n",
       "1591               Okay. You know where to find me.  \n",
       "\n",
       "[1592 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ffill(axis = 0,inplace=True) # fills the null value with the previous value.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s get into our first step, text normalization where we convert the data into lower case and then remove special characters and then perform lemmatization.\n",
    "\n",
    "Let us create a function that converts given text to lower case and removes special characters and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.head(10) # copy of first ten rows of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that converts text into lower case and removes special characters\n",
    "def step1(x):\n",
    "    for i in x:\n",
    "        a=str(i).lower()\n",
    "        p=re.sub(r'[^a-z0-9]',' ',a)\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tell me about your personality\n",
      "i want to know you better\n",
      "define yourself\n",
      "describe yourself\n",
      "tell me about yourself\n",
      "all about you\n",
      "tell me some stuff about you\n",
      "talk some stuff about you\n",
      "talk about yourself\n",
      "about yourself\n"
     ]
    }
   ],
   "source": [
    "step1(df1['Context'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our text is clean. Word tokenizing is the process of converting the normal text strings into a list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tell', 'me', 'about', 'your', 'personality']\n"
     ]
    }
   ],
   "source": [
    "# word tokenizing\n",
    "s = 'tell me about your personality'\n",
    "words = word_tokenize(s)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **pos_tag** function returns the parts of speech of each token so that the lemmatizer function detects the parts of speech of token and then it converts the token to its root word as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'absorb'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = wordnet.WordNetLemmatizer() # intializing lemmatizer\n",
    "lemma.lemmatize('absorbed', pos = 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tell', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('about', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('personality', 'NN')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(nltk.word_tokenize(s),tagset = None) # returns the parts of speech of every word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now create a function that performs all the steps mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that performs text normalization steps\n",
    "\n",
    "def text_normalization(text):\n",
    "    text=str(text).lower() # text to lower case\n",
    "    spl_char_text=re.sub(r'[^ a-z]','',text) # removing special characters\n",
    "    tokens=nltk.word_tokenize(spl_char_text) # word tokenizing\n",
    "    lema=wordnet.WordNetLemmatizer() # intializing lemmatization\n",
    "    tags_list=pos_tag(tokens,tagset=None) # parts of speech\n",
    "    lema_words=[]   # empty list \n",
    "    for token,pos_token in tags_list:\n",
    "        if pos_token.startswith('V'):  # Verb\n",
    "            pos_val='v'\n",
    "        elif pos_token.startswith('J'): # Adjective\n",
    "            pos_val='a'\n",
    "        elif pos_token.startswith('R'): # Adverb\n",
    "            pos_val='r'\n",
    "        else:\n",
    "            pos_val='n' # Noun\n",
    "        lema_token=lema.lemmatize(token,pos_val) # performing lemmatization\n",
    "        lema_words.append(lema_token) # appending the lemmatized token into a list\n",
    "    \n",
    "    return \" \".join(lema_words) # returns the lemmatized tokens as a sentence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check our function and apply it to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tell you some stuff about me'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_normalization('telling you some stuff about me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Text Response</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>I need to talk to you</td>\n",
       "      <td>Good conversation really makes my day.</td>\n",
       "      <td>i need to talk to you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>I want to speak with you</td>\n",
       "      <td>I'm always here to lend an ear.</td>\n",
       "      <td>i want to speak with you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>let's have a discussion</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>let have a discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>I just want to talk</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>i just want to talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>let's discuss something</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>let discuss something</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>can I speak</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>can i speak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>can we talk</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>can we talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>let's talk</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>let talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>I want to talk to you</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>i want to talk to you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>can we chat</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>can we chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>can we chat</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>can we chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>I'll be back in a few minutes</td>\n",
       "      <td>I'll be waiting.</td>\n",
       "      <td>ill be back in a few minute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>I'll be back</td>\n",
       "      <td>All right. I'll be here.</td>\n",
       "      <td>ill be back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>I'll get back to you in a moment</td>\n",
       "      <td>Till next time.</td>\n",
       "      <td>ill get back to you in a moment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>I promise to come back</td>\n",
       "      <td>Okay. You know where to find me.</td>\n",
       "      <td>i promise to come back</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Context  \\\n",
       "1577             I need to talk to you   \n",
       "1578          I want to speak with you   \n",
       "1579           let's have a discussion   \n",
       "1580               I just want to talk   \n",
       "1581           let's discuss something   \n",
       "1582                       can I speak   \n",
       "1583                       can we talk   \n",
       "1584                        let's talk   \n",
       "1585             I want to talk to you   \n",
       "1586                       can we chat   \n",
       "1587                       can we chat   \n",
       "1588     I'll be back in a few minutes   \n",
       "1589                      I'll be back   \n",
       "1590  I'll get back to you in a moment   \n",
       "1591            I promise to come back   \n",
       "\n",
       "                               Text Response                  lemmatized_text  \n",
       "1577  Good conversation really makes my day.            i need to talk to you  \n",
       "1578         I'm always here to lend an ear.         i want to speak with you  \n",
       "1579              Talking is what I do best.            let have a discussion  \n",
       "1580              Talking is what I do best.              i just want to talk  \n",
       "1581              Talking is what I do best.            let discuss something  \n",
       "1582              Talking is what I do best.                      can i speak  \n",
       "1583              Talking is what I do best.                      can we talk  \n",
       "1584              Talking is what I do best.                         let talk  \n",
       "1585              Talking is what I do best.            i want to talk to you  \n",
       "1586              Talking is what I do best.                      can we chat  \n",
       "1587              Talking is what I do best.                      can we chat  \n",
       "1588                        I'll be waiting.      ill be back in a few minute  \n",
       "1589                All right. I'll be here.                      ill be back  \n",
       "1590                         Till next time.  ill get back to you in a moment  \n",
       "1591        Okay. You know where to find me.           i promise to come back  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmatized_text']=df['Context'].apply(text_normalization) # applying the fuction to the dataset to get clean text\n",
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our function worked well and thus we applied the same to our data. Our next step is word embedding, it is representation for text where words that have the same meaning have a similar representation. We have two models for this process bag of words (bow) and tf-idf ( Term Frequency-Inverse Document Frequency)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bag-of-words is a representation of text that describes the occurrence of words within a document. Consider if our dictionary contains the words {Playing, is, love}, and we want to vectorize the text “Playing football is love”, we would have the following vector: (1, 0, 1, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer() # intializing the count vectorizer\n",
    "X = cv.fit_transform(df['lemmatized_text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abort</th>\n",
       "      <th>about</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abysmal</th>\n",
       "      <th>actually</th>\n",
       "      <th>adore</th>\n",
       "      <th>advice</th>\n",
       "      <th>advise</th>\n",
       "      <th>affirmative</th>\n",
       "      <th>afraid</th>\n",
       "      <th>...</th>\n",
       "      <th>yeh</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>youre</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abort  about  absolutely  abysmal  actually  adore  advice  advise  \\\n",
       "0      0      1           0        0         0      0       0       0   \n",
       "1      0      0           0        0         0      0       0       0   \n",
       "2      0      0           0        0         0      0       0       0   \n",
       "3      0      0           0        0         0      0       0       0   \n",
       "4      0      1           0        0         0      0       0       0   \n",
       "\n",
       "   affirmative  afraid  ...  yeh  yep  yes  yet  you  your  youre  yours  \\\n",
       "0            0       0  ...    0    0    0    0    0     1      0      0   \n",
       "1            0       0  ...    0    0    0    0    1     0      0      0   \n",
       "2            0       0  ...    0    0    0    0    0     0      0      0   \n",
       "3            0       0  ...    0    0    0    0    0     0      0      0   \n",
       "4            0       0  ...    0    0    0    0    0     0      0      0   \n",
       "\n",
       "   yourself  yup  \n",
       "0         0    0  \n",
       "1         0    0  \n",
       "2         1    0  \n",
       "3         1    0  \n",
       "4         1    0  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns all the unique word from data \n",
    "\n",
    "features = cv.get_feature_names()\n",
    "df_bow = pd.DataFrame(X, columns = features)\n",
    "df_bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the row 0 of the dataset the bow marks all the words present in the text as 1 and rest as 0.\n",
    "\n",
    "Stop words are extremely common words that would appear to be of little value in matching a user’s need and hence they are excluded from the vocabulary entirely. Below are the predefined stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# all the stop words we have \n",
    "\n",
    "stop = stopwords.words('english')\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider an example and try getting a response to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question ='Will you help me and tell me about yourself more' # considering an example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for stop words\n",
    "\n",
    "Q=[]\n",
    "a=Question.split()\n",
    "for i in a:\n",
    "    if i in stop:\n",
    "        continue\n",
    "    else:\n",
    "        Q.append(i)\n",
    "    b=\" \".join(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_lemma = text_normalization(b) # applying the function that we created for text normalizing\n",
    "Question_bow = cv.transform([Question_lemma]).toarray() # applying bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.text_normalization(text)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Question_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above We can see that we have taken a question ‘Will you help me and tell me about yourself more’ and then perform text normalization and then applying the bow to the question. Now to get the related response we shall find the cosine similarity between the question and the lemmatized text we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity :\n",
    "\n",
    "Cosine similarity is a measure of similarity between two vectors. It returns a value that is computed by taking the dot product and dividing that by the product of their norms between two vectors.\n",
    "\n",
    "#### Cosine Similarity (a, b) = Dot product(a, b) / ||a|| * ||b||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25819889],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       ...,\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine similarity for the above question we considered.\n",
    "\n",
    "cosine_value = 1- pairwise_distances(df_bow, Question_bow, metric = 'cosine' )\n",
    "(cosine_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['similarity_bow']=cosine_value # creating a new column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Response</th>\n",
       "      <th>similarity_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>I'll be waiting.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>All right. I'll be here.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>Till next time.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>Okay. You know where to find me.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1592 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text Response  similarity_bow\n",
       "0       Just think of me as the ace up your sleeve.        0.258199\n",
       "1     I can help you work smarter instead of harder        0.000000\n",
       "2     I can help you work smarter instead of harder        0.000000\n",
       "3     I can help you work smarter instead of harder        0.000000\n",
       "4     I can help you work smarter instead of harder        0.288675\n",
       "...                                             ...             ...\n",
       "1587                     Talking is what I do best.        0.000000\n",
       "1588                               I'll be waiting.        0.000000\n",
       "1589                       All right. I'll be here.        0.000000\n",
       "1590                                Till next time.        0.000000\n",
       "1591               Okay. You know where to find me.        0.000000\n",
       "\n",
       "[1592 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simi = pd.DataFrame(df, columns=['Text Response','similarity_bow']) # taking similarity value of responses for the question we took\n",
    "df_simi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Response</th>\n",
       "      <th>similarity_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Text Response  similarity_bow\n",
       "211  I'm glad to help. What can I do for you?        0.577350\n",
       "194  I'm glad to help. What can I do for you?        0.577350\n",
       "184  I'm glad to help. What can I do for you?        0.408248\n",
       "186  I'm glad to help. What can I do for you?        0.408248\n",
       "200  I'm glad to help. What can I do for you?        0.408248"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simi_sort = df_simi.sort_values(by='similarity_bow', ascending=False) # sorting the values\n",
    "df_simi_sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Response</th>\n",
       "      <th>similarity_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>It's my pleasure to help.</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Oh, don't give up on me!</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>If you're happy, then I'm happy.</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>Probably I won't be able to give you the right...</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>It's my pleasure to help.</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Of course I am.</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Oh, don't give up on me!</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I'm a relatively new bot, but I'm wise beyond ...</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>I'm not programmed for that exact question. Tr...</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>I'm sorry you think so. I'm constantly learnin...</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>My pleasure.</td>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>The virtual world is my playground. I'm always...</td>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>I should get one. It's all work and no play la...</td>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Sure. I'd be happy to. What's up?</td>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>Absolutely. You don't have to ask.</td>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>It's my pleasure to help.</td>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "      <td>0.258199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>It's my pleasure to help.</td>\n",
       "      <td>0.235702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Absolutely. You don't have to ask.</td>\n",
       "      <td>0.235702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.235702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.235702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.235702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.235702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.235702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Thanks, I try.</td>\n",
       "      <td>0.218218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>It's my pleasure to help.</td>\n",
       "      <td>0.218218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Thanks, I try.</td>\n",
       "      <td>0.204124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>So I see. What can I help you with today?</td>\n",
       "      <td>0.204124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text Response  similarity_bow\n",
       "211            I'm glad to help. What can I do for you?        0.577350\n",
       "194            I'm glad to help. What can I do for you?        0.577350\n",
       "184            I'm glad to help. What can I do for you?        0.408248\n",
       "186            I'm glad to help. What can I do for you?        0.408248\n",
       "200            I'm glad to help. What can I do for you?        0.408248\n",
       "219            I'm glad to help. What can I do for you?        0.333333\n",
       "728                           It's my pleasure to help.        0.333333\n",
       "188            I'm glad to help. What can I do for you?        0.333333\n",
       "190            I'm glad to help. What can I do for you?        0.333333\n",
       "191            I'm glad to help. What can I do for you?        0.333333\n",
       "197            I'm glad to help. What can I do for you?        0.333333\n",
       "199            I'm glad to help. What can I do for you?        0.333333\n",
       "214            I'm glad to help. What can I do for you?        0.333333\n",
       "216            I'm glad to help. What can I do for you?        0.333333\n",
       "220            I'm glad to help. What can I do for you?        0.333333\n",
       "221            I'm glad to help. What can I do for you?        0.333333\n",
       "222            I'm glad to help. What can I do for you?        0.333333\n",
       "288                            Oh, don't give up on me!        0.333333\n",
       "1364                   If you're happy, then I'm happy.        0.288675\n",
       "1506  Probably I won't be able to give you the right...        0.288675\n",
       "727                           It's my pleasure to help.        0.288675\n",
       "4         I can help you work smarter instead of harder        0.288675\n",
       "515                                     Of course I am.        0.288675\n",
       "289                            Oh, don't give up on me!        0.288675\n",
       "218            I'm glad to help. What can I do for you?        0.288675\n",
       "196            I'm glad to help. What can I do for you?        0.288675\n",
       "24    I'm a relatively new bot, but I'm wise beyond ...        0.288675\n",
       "210            I'm glad to help. What can I do for you?        0.288675\n",
       "48    I'm not programmed for that exact question. Tr...        0.288675\n",
       "212            I'm glad to help. What can I do for you?        0.288675\n",
       "213            I'm glad to help. What can I do for you?        0.288675\n",
       "16        I can help you work smarter instead of harder        0.288675\n",
       "61    I'm sorry you think so. I'm constantly learnin...        0.288675\n",
       "205            I'm glad to help. What can I do for you?        0.258199\n",
       "538                                        My pleasure.        0.258199\n",
       "500   The virtual world is my playground. I'm always...        0.258199\n",
       "185            I'm glad to help. What can I do for you?        0.258199\n",
       "379   I should get one. It's all work and no play la...        0.258199\n",
       "183                   Sure. I'd be happy to. What's up?        0.258199\n",
       "414                  Absolutely. You don't have to ask.        0.258199\n",
       "747                           It's my pleasure to help.        0.258199\n",
       "0           Just think of me as the ace up your sleeve.        0.258199\n",
       "733                           It's my pleasure to help.        0.235702\n",
       "419                  Absolutely. You don't have to ask.        0.235702\n",
       "193            I'm glad to help. What can I do for you?        0.235702\n",
       "195            I'm glad to help. What can I do for you?        0.235702\n",
       "209            I'm glad to help. What can I do for you?        0.235702\n",
       "189            I'm glad to help. What can I do for you?        0.235702\n",
       "6         I can help you work smarter instead of harder        0.235702\n",
       "330                                      Thanks, I try.        0.218218\n",
       "738                           It's my pleasure to help.        0.218218\n",
       "341                                      Thanks, I try.        0.204124\n",
       "1377          So I see. What can I help you with today?        0.204124"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.2 # considering the value of p=smiliarity to be greater than 0.2\n",
    "df_threshold = df_simi_sort[df_simi_sort['similarity_bow'] > threshold] \n",
    "df_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally using bow for the question 'Will you help me and tell me about yourself more' , the above are the responses we got using bow and the smiliarity value of responses, we consider the response with highest similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_value = cosine_value.argmax() # returns the index number of highest value\n",
    "index_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that at index 194 we have the highest similarity text for the query we considered. Let us print the text at that position and see whether it is related or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Will you help me and tell me about yourself more'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm glad to help. What can I do for you?\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text Response'].loc[index_value] # The text at the above index becomes the response for the question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our model worked pretty well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tf-idf :\n",
    "\n",
    "tf is **Term Frequency**, scoring of the frequency of the word in the current document and idf is **Inverse Document Frequency**, scoring of how rare the word is across documents. Here document represents a single text, say row 0 or row1, etc, where documents refer to all the rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using tf-idf\n",
    "\n",
    "tfidf=TfidfVectorizer() # intializing tf-id \n",
    "x_tfidf=tfidf.fit_transform(df['lemmatized_text']).toarray() # transforming the data into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abort</th>\n",
       "      <th>about</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abysmal</th>\n",
       "      <th>actually</th>\n",
       "      <th>adore</th>\n",
       "      <th>advice</th>\n",
       "      <th>advise</th>\n",
       "      <th>affirmative</th>\n",
       "      <th>afraid</th>\n",
       "      <th>...</th>\n",
       "      <th>yeh</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>youre</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.330555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641790</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641790</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abort     about  absolutely  abysmal  actually  adore  advice  advise  \\\n",
       "0    0.0  0.407572         0.0      0.0       0.0    0.0     0.0     0.0   \n",
       "1    0.0  0.000000         0.0      0.0       0.0    0.0     0.0     0.0   \n",
       "2    0.0  0.000000         0.0      0.0       0.0    0.0     0.0     0.0   \n",
       "3    0.0  0.000000         0.0      0.0       0.0    0.0     0.0     0.0   \n",
       "4    0.0  0.453790         0.0      0.0       0.0    0.0     0.0     0.0   \n",
       "\n",
       "   affirmative  afraid  ...  yeh  yep  yes  yet       you      your  youre  \\\n",
       "0          0.0     0.0  ...  0.0  0.0  0.0  0.0  0.000000  0.330555    0.0   \n",
       "1          0.0     0.0  ...  0.0  0.0  0.0  0.0  0.218768  0.000000    0.0   \n",
       "2          0.0     0.0  ...  0.0  0.0  0.0  0.0  0.000000  0.000000    0.0   \n",
       "3          0.0     0.0  ...  0.0  0.0  0.0  0.0  0.000000  0.000000    0.0   \n",
       "4          0.0     0.0  ...  0.0  0.0  0.0  0.0  0.000000  0.000000    0.0   \n",
       "\n",
       "   yours  yourself  yup  \n",
       "0    0.0  0.000000  0.0  \n",
       "1    0.0  0.000000  0.0  \n",
       "2    0.0  0.641790  0.0  \n",
       "3    0.0  0.641790  0.0  \n",
       "4    0.0  0.608937  0.0  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns all the unique word from data with a score of that word\n",
    "\n",
    "df_tfidf=pd.DataFrame(x_tfidf,columns=tfidf.get_feature_names()) \n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above are the values obtained using tf-idf. Now using cosine similarity lets us find the response that we get with tf-idf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question1 ='Tell me about yourself.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_lemma1 = text_normalization(Question1)\n",
    "Question_tfidf = tfidf.transform([Question_lemma1]).toarray() # applying tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56511191],\n",
       "       [0.        ],\n",
       "       [0.39080996],\n",
       "       ...,\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos=1-pairwise_distances(df_tfidf,Question_tfidf,metric='cosine')  # applying cosine similarity\n",
    "cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Response</th>\n",
       "      <th>similarity_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "      <td>0.565112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.390810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.390810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>I'll be waiting.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>All right. I'll be here.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>Till next time.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>Okay. You know where to find me.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1592 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text Response  similarity_tfidf\n",
       "0       Just think of me as the ace up your sleeve.          0.565112\n",
       "1     I can help you work smarter instead of harder          0.000000\n",
       "2     I can help you work smarter instead of harder          0.390810\n",
       "3     I can help you work smarter instead of harder          0.390810\n",
       "4     I can help you work smarter instead of harder          1.000000\n",
       "...                                             ...               ...\n",
       "1587                     Talking is what I do best.          0.000000\n",
       "1588                               I'll be waiting.          0.000000\n",
       "1589                       All right. I'll be here.          0.000000\n",
       "1590                                Till next time.          0.000000\n",
       "1591               Okay. You know where to find me.          0.000000\n",
       "\n",
       "[1592 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['similarity_tfidf']=cos # creating a new column \n",
    "df_simi_tfidf = pd.DataFrame(df, columns=['Text Response','similarity_tfidf']) # taking similarity value of responses for the question we took\n",
    "df_simi_tfidf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Response</th>\n",
       "      <th>similarity_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.771758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.759428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.651909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>I should get one. It's all work and no play la...</td>\n",
       "      <td>0.594479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>The virtual world is my playground. I'm always...</td>\n",
       "      <td>0.590474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "      <td>0.565112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.514553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>I'm not programmed for that exact question. Tr...</td>\n",
       "      <td>0.445403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I'm a relatively new bot, but I'm wise beyond ...</td>\n",
       "      <td>0.434832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Text Response  similarity_tfidf\n",
       "4        I can help you work smarter instead of harder          1.000000\n",
       "16       I can help you work smarter instead of harder          0.771758\n",
       "9        I can help you work smarter instead of harder          0.759428\n",
       "8        I can help you work smarter instead of harder          0.651909\n",
       "379  I should get one. It's all work and no play la...          0.594479\n",
       "500  The virtual world is my playground. I'm always...          0.590474\n",
       "0          Just think of me as the ace up your sleeve.          0.565112\n",
       "6        I can help you work smarter instead of harder          0.514553\n",
       "48   I'm not programmed for that exact question. Tr...          0.445403\n",
       "24   I'm a relatively new bot, but I'm wise beyond ...          0.434832"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simi_tfidf_sort = df_simi_tfidf.sort_values(by='similarity_tfidf', ascending=False) # sorting the values\n",
    "df_simi_tfidf_sort.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Response</th>\n",
       "      <th>similarity_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.771758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.759428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.651909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>I should get one. It's all work and no play la...</td>\n",
       "      <td>0.594479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>The virtual world is my playground. I'm always...</td>\n",
       "      <td>0.590474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "      <td>0.565112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.514553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>I'm not programmed for that exact question. Tr...</td>\n",
       "      <td>0.445403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I'm a relatively new bot, but I'm wise beyond ...</td>\n",
       "      <td>0.434832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.390810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.390810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.390810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>Lovely, thanks.</td>\n",
       "      <td>0.317730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>Probably I won't be able to give you the right...</td>\n",
       "      <td>0.293930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>Probably I won't be able to give you the right...</td>\n",
       "      <td>0.293930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.284758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.282998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>Okay then.</td>\n",
       "      <td>0.278265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Of course I am.</td>\n",
       "      <td>0.277953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>Thanks! The feeling is mutual.</td>\n",
       "      <td>0.275350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Cancelled. Go on with the commands!</td>\n",
       "      <td>0.258578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>That's all right. I forgive you.</td>\n",
       "      <td>0.257507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>Cancelled. Go on with the commands!</td>\n",
       "      <td>0.250630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>That's all right. I forgive you.</td>\n",
       "      <td>0.243373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Of course I am.</td>\n",
       "      <td>0.239825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Thanks, I try.</td>\n",
       "      <td>0.238327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Thanks, I try.</td>\n",
       "      <td>0.237712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>Thanks! The feeling is mutual.</td>\n",
       "      <td>0.237025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>Lovely, thanks.</td>\n",
       "      <td>0.232481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Oh no! My best work is yet to come.</td>\n",
       "      <td>0.226665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.221686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>Cancelled. Go on with the commands!</td>\n",
       "      <td>0.221333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>I should get one. It's all work and no play la...</td>\n",
       "      <td>0.217804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>I should get one. It's all work and no play la...</td>\n",
       "      <td>0.217804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Thanks, I try.</td>\n",
       "      <td>0.216600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>Good deal.</td>\n",
       "      <td>0.215417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>I'm glad to help. What can I do for you?</td>\n",
       "      <td>0.210776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>So I see. What can I help you with today?</td>\n",
       "      <td>0.208397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Can you try asking it a different way?</td>\n",
       "      <td>0.207035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Hug it out. You'll feel better afterwards.</td>\n",
       "      <td>0.201679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Hug it out. You'll feel better afterwards.</td>\n",
       "      <td>0.201679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>Hug it out. You'll feel better afterwards.</td>\n",
       "      <td>0.201679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>Probably I won't be able to give you the right...</td>\n",
       "      <td>0.200153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text Response  similarity_tfidf\n",
       "4         I can help you work smarter instead of harder          1.000000\n",
       "16        I can help you work smarter instead of harder          0.771758\n",
       "9         I can help you work smarter instead of harder          0.759428\n",
       "8         I can help you work smarter instead of harder          0.651909\n",
       "379   I should get one. It's all work and no play la...          0.594479\n",
       "500   The virtual world is my playground. I'm always...          0.590474\n",
       "0           Just think of me as the ace up your sleeve.          0.565112\n",
       "6         I can help you work smarter instead of harder          0.514553\n",
       "48    I'm not programmed for that exact question. Tr...          0.445403\n",
       "24    I'm a relatively new bot, but I'm wise beyond ...          0.434832\n",
       "11        I can help you work smarter instead of harder          0.390810\n",
       "3         I can help you work smarter instead of harder          0.390810\n",
       "2         I can help you work smarter instead of harder          0.390810\n",
       "1203                                    Lovely, thanks.          0.317730\n",
       "1527  Probably I won't be able to give you the right...          0.293930\n",
       "1526  Probably I won't be able to give you the right...          0.293930\n",
       "15        I can help you work smarter instead of harder          0.284758\n",
       "5         I can help you work smarter instead of harder          0.282998\n",
       "878                                          Okay then.          0.278265\n",
       "515                                     Of course I am.          0.277953\n",
       "1436                     Thanks! The feeling is mutual.          0.275350\n",
       "791                 Cancelled. Go on with the commands!          0.258578\n",
       "1030                   That's all right. I forgive you.          0.257507\n",
       "806                 Cancelled. Go on with the commands!          0.250630\n",
       "1037                   That's all right. I forgive you.          0.243373\n",
       "516                                     Of course I am.          0.239825\n",
       "330                                      Thanks, I try.          0.238327\n",
       "341                                      Thanks, I try.          0.237712\n",
       "1403                     Thanks! The feeling is mutual.          0.237025\n",
       "1208                                    Lovely, thanks.          0.232481\n",
       "285                 Oh no! My best work is yet to come.          0.226665\n",
       "184            I'm glad to help. What can I do for you?          0.221686\n",
       "817                 Cancelled. Go on with the commands!          0.221333\n",
       "381   I should get one. It's all work and no play la...          0.217804\n",
       "382   I should get one. It's all work and no play la...          0.217804\n",
       "332                                      Thanks, I try.          0.216600\n",
       "714                                          Good deal.          0.215417\n",
       "214            I'm glad to help. What can I do for you?          0.210776\n",
       "1377          So I see. What can I help you with today?          0.208397\n",
       "40               Can you try asking it a different way?          0.207035\n",
       "996          Hug it out. You'll feel better afterwards.          0.201679\n",
       "1000         Hug it out. You'll feel better afterwards.          0.201679\n",
       "1003         Hug it out. You'll feel better afterwards.          0.201679\n",
       "1518  Probably I won't be able to give you the right...          0.200153"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.2 # considering the value of p=smiliarity to be greater than 0.2\n",
    "df_threshold = df_simi_tfidf_sort[df_simi_tfidf_sort['similarity_tfidf'] > threshold] \n",
    "df_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- by using tfidf for the question 'Will you help me and tell me about yourself more' , the above are the responses we got and the smiliarity value of responses, we consider the response with highest similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_value1 = cos.argmax() # returns the index number of highest value\n",
    "index_value1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At index 4 we got higher similarity text that relates to our question. Let us see the response to our question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me about yourself.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I can help you work smarter instead of harder'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text Response'].loc[index_value1]  # returns the text at that index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tf-idf we got a different response which is also a pretty good response to the question.\n",
    "\n",
    "Now let’s build a function that returns the response to the query using Bag of Words and tf-idf. It is very simple we just have to combine all the topics we saw earlier in this article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that removes stop words and process the text\n",
    "\n",
    "def stopword_(text):   \n",
    "    tag_list=pos_tag(nltk.word_tokenize(text),tagset=None)\n",
    "    stop=stopwords.words('english')\n",
    "    lema=wordnet.WordNetLemmatizer()\n",
    "    lema_word=[]\n",
    "    for token,pos_token in tag_list:\n",
    "        if token in stop:\n",
    "            continue\n",
    "        if pos_token.startswith('V'):\n",
    "            pos_val='v'\n",
    "        elif pos_token.startswith('J'):\n",
    "            pos_val='a'\n",
    "        elif pos_token.startswith('R'):\n",
    "            pos_val='r'\n",
    "        else:\n",
    "            pos_val='n'\n",
    "        lema_token=lema.lemmatize(token,pos_val)\n",
    "        lema_word.append(lema_token)\n",
    "    return \" \".join(lema_word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function that returns response to query using bow\n",
    "\n",
    "def chat_bow(text):\n",
    "    s=stopword_(text)\n",
    "    lemma=text_normalization(s) # calling the function to perform text normalization\n",
    "    bow=cv.transform([lemma]).toarray() # applying bow\n",
    "    cosine_value = 1- pairwise_distances(df_bow,bow, metric = 'cosine' )\n",
    "    index_value=cosine_value.argmax() # getting index value \n",
    "    return df['Text Response'].loc[index_value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see some output responses for a different queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey!'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_bow('hi there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Terrific!'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_bow('Your are amazing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've been right here all along!\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_bow('i miss you')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function that returns response to query using tf-idf\n",
    "\n",
    "def chat_tfidf(text):\n",
    "    lemma=text_normalization(text) # calling the function to perform text normalization\n",
    "    tf=tfidf.transform([lemma]).toarray() # applying tf-idf\n",
    "    cos=1-pairwise_distances(df_tfidf,tf,metric='cosine') # applying cosine similarity\n",
    "    index_value=cos.argmax() # getting index value \n",
    "    return df['Text Response'].loc[index_value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see some output responses for a different queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey!'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_tfidf('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lovely, thanks.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_tfidf('how are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's great to hear.\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_tfidf('i love you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's my pleasure to help.\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_tfidf('thanks for your support!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh, don't give up on me!\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_tfidf('will you reply accurately?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the virtual sense that I can, sure.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_tfidf('will you marry me?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've been right here all along!\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_tfidf('i miss you and i love you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oops. Sorry about that. I'm still learning.\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_tfidf('ask sravya to read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bye.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_tfidf('you are amazing and hope to see u soon.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "The model we built doesn’t have any artificial intelligence, but still, it responded pretty well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
